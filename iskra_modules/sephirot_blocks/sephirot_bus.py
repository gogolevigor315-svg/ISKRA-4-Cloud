 # sephirot_bus.py - –°–û–í–ï–†–®–ï–ù–ù–ê–Ø –°–ï–§–ò–†–û–¢–ò–ß–ï–°–ö–ê–Ø –®–ò–ù–ê (–ò–î–ï–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø)
import asyncio
import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple
from dataclasses import dataclass, field
from collections import deque, defaultdict
import statistics
import yaml
from enum import Enum

from .sephirot_base import (
    SephiroticNode, QuantumLink, SignalPackage, 
    SignalType, NodeStatus, ResonancePhase, NodeMetrics
)


class ChannelDirection(Enum):
    """–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞"""
    FORWARD = "forward"      # –ü—Ä—è–º–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    REVERSE = "reverse"      # –û–±—Ä–∞—Ç–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    BIDIRECTIONAL = "bidirectional"  # –î–≤—É—Å—Ç–æ—Ä–æ–Ω–Ω–∏–π


@dataclass
class QuantumChannel:
    """–ö–≤–∞–Ω—Ç–æ–≤—ã–π –∫–∞–Ω–∞–ª –î—Ä–µ–≤–∞ –ñ–∏–∑–Ω–∏ —Å –ø–æ–ª–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–æ–π"""
    
    # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
    id: str
    hebrew_letter: str
    from_sephira: str
    to_sephira: str
    
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    base_strength: float = 0.8          # –ë–∞–∑–æ–≤–∞—è —Å–∏–ª–∞ (0.0-1.0)
    current_strength: float = 0.8       # –¢–µ–∫—É—â–∞—è —Å–∏–ª–∞ —Å —É—á–µ—Ç–æ–º —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞
    resonance_factor: float = 1.0       # –§–∞–∫—Ç–æ—Ä —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞ (0.1-2.0)
    energy_decay: float = 0.95          # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è —ç–Ω–µ—Ä–≥–∏–∏
    learning_rate: float = 0.01         # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –∫–∞–Ω–∞–ª–∞
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    direction: ChannelDirection = ChannelDirection.BIDIRECTIONAL
    max_bandwidth: int = 100            # –ú–∞–∫—Å —Å–∏–≥–Ω–∞–ª–æ–≤/—Å–µ–∫
    current_load: int = 0               # –¢–µ–∫—É—â–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
    is_active: bool = True              # –ê–∫—Ç–∏–≤–µ–Ω –ª–∏ –∫–∞–Ω–∞–ª
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    description: str = ""
    created: datetime = field(default_factory=datetime.utcnow)
    last_used: Optional[datetime] = None
    last_optimized: Optional[datetime] = None
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    total_transmissions: int = 0
    successful_transmissions: int = 0
    failed_transmissions: int = 0
    avg_latency: float = 0.0
    avg_signal_strength: float = 0.0
    
    # –ò—Å—Ç–æ—Ä–∏—è
    strength_history: deque = field(default_factory=lambda: deque(maxlen=100))
    resonance_history: deque = field(default_factory=lambda: deque(maxlen=100))
    latency_history: deque = field(default_factory=lambda: deque(maxlen=100))
    
    def __post_init__(self):
        """–ü–æ—Å—Ç-–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        if not self.description:
            self.description = f"–ü—É—Ç—å {self.hebrew_letter}: {self.from_sephira} ‚Üí {self.to_sephira}"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏
        self.strength_history.append(self.current_strength)
        self.resonance_history.append(self.resonance_factor)
    
    async def can_transmit(self, signal_strength: float = 1.0) -> Tuple[bool, str, float]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ–¥–∞—á–∏ —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Å–∏–ª—ã
        
        Returns:
            Tuple[bool, str, float]: (–º–æ–∂–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å, –ø—Ä–∏—á–∏–Ω–∞, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å–∏–ª–∞)
        """
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        if not self.is_active:
            return False, "channel_inactive", 0.0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏
        load_percentage = self.current_load / self.max_bandwidth if self.max_bandwidth > 0 else 0
        if load_percentage > 0.9:
            return False, "channel_overloaded", 0.0
        
        # –†–∞—Å—á–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Å–∏–ª—ã
        effective_strength = (
            self.current_strength * 
            self.resonance_factor * 
            signal_strength * 
            (1 - load_percentage * 0.5)
        )
        
        if effective_strength < 0.05:
            return False, "signal_too_weak", effective_strength
        
        return True, "can_transmit", effective_strength
    
    async def calculate_signal_transform(self, signal_package: SignalPackage, 
                                        distance: int = 1) -> Tuple[SignalPackage, float, Dict[str, Any]]:
        """
        –†–∞—Å—á–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–∞ –ø—Ä–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ –∫–∞–Ω–∞–ª
        
        Returns:
            Tuple[modified_signal, remaining_strength, diagnostics]
        """
        diagnostics = {
            "channel_id": self.id,
            "base_strength": self.current_strength,
            "resonance_factor": self.resonance_factor,
            "distance": distance
        }
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª –¥–ª—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
        modified_signal = signal_package.copy()
        
        # –†–∞—Å—á–µ—Ç –ø–æ—Ç–µ—Ä—å
        distance_loss = 0.1 * (distance - 1)
        load_loss = (self.current_load / self.max_bandwidth) * 0.3
        resonance_gain = (self.resonance_factor - 1.0) * 0.2
        
        total_loss = max(0.0, distance_loss + load_loss - resonance_gain)
        remaining_strength = 1.0 - total_loss
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å –∫ —Å–∏–ª–µ —Å–∏–≥–Ω–∞–ª–∞
        if hasattr(modified_signal, 'strength'):
            modified_signal.strength *= remaining_strength
        
        # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è payload –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–∞–Ω–∞–ª–∞
        if hasattr(modified_signal, 'payload'):
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ –∫–∞–Ω–∞–ª
            channel_info = {
                "channel_id": self.id,
                "hebrew_letter": self.hebrew_letter,
                "strength_impact": remaining_strength,
                "resonance_impact": self.resonance_factor,
                "timestamp": datetime.utcnow().isoformat()
            }
            
            if "channel_history" not in modified_signal.payload:
                modified_signal.payload["channel_history"] = []
            modified_signal.payload["channel_history"].append(channel_info)
            
            # –£—Å–∏–ª–µ–Ω–∏–µ/–æ—Å–ª–∞–±–ª–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
            if modified_signal.type == SignalType.EMOTIONAL:
                # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è —Ä–µ–∑–æ–Ω–∞–Ω—Å–æ–º
                if "intensity" in modified_signal.payload:
                    modified_signal.payload["intensity"] *= (1.0 + (self.resonance_factor - 1.0) * 0.5)
            
            elif modified_signal.type == SignalType.INTENTION:
                # –ù–∞–º–µ—Ä–µ–Ω–∏—è —É—Å–∏–ª–∏–≤–∞—é—Ç—Å—è —Å–∏–ª–æ–π –∫–∞–Ω–∞–ª–∞
                if "strength" in modified_signal.payload:
                    modified_signal.payload["strength"] *= self.current_strength
        
        diagnostics.update({
            "total_loss": total_loss,
            "remaining_strength": remaining_strength,
            "modified_signal_type": modified_signal.type.value
        })
        
        return modified_signal, remaining_strength, diagnostics
    
    async def update_from_transmission(self, success: bool, latency: float, 
                                      final_strength: float, signal_type: SignalType):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–µ—Ä–µ–¥–∞—á–∏"""
        self.total_transmissions += 1
        
        if success:
            self.successful_transmissions += 1
            
            # –£—Å–∏–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π –ø–µ—Ä–µ–¥–∞—á–µ
            learning_adjustment = self.learning_rate * final_strength
            
            # –†–∞–∑–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
            if signal_type == SignalType.QUANTUM_SYNC:
                learning_adjustment *= 1.5  # –ö–≤–∞–Ω—Ç–æ–≤–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —É—á–∏—Ç –±—ã—Å—Ç—Ä–µ–µ
            elif signal_type == SignalType.EMOTIONAL:
                learning_adjustment *= 1.2  # –≠–º–æ—Ü–∏–∏ —Ç–∞–∫–∂–µ —Ö–æ—Ä–æ—à–æ —É—á–∞—Ç
            
            self.current_strength = min(1.0, self.current_strength + learning_adjustment)
            self.resonance_factor = min(2.0, self.resonance_factor + learning_adjustment * 0.5)
            
        else:
            self.failed_transmissions += 1
            
            # –û—Å–ª–∞–±–ª–µ–Ω–∏–µ –ø—Ä–∏ –Ω–µ—É–¥–∞—á–µ, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º —Ä–µ–∑–∫–æ–µ
            penalty = self.learning_rate * 0.5
            self.current_strength = max(0.1, self.current_strength - penalty)
            self.resonance_factor = max(0.1, self.resonance_factor - penalty * 0.3)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –ª–∞—Ç–µ–Ω—Ü–∏–∏
        if self.avg_latency == 0:
            self.avg_latency = latency
        else:
            self.avg_latency = (self.avg_latency * 0.9) + (latency * 0.1)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π —Å–∏–ª—ã
        if self.avg_signal_strength == 0:
            self.avg_signal_strength = final_strength
        else:
            self.avg_signal_strength = (self.avg_signal_strength * 0.9) + (final_strength * 0.1)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.strength_history.append(self.current_strength)
        self.resonance_history.append(self.resonance_factor)
        self.latency_history.append(latency)
        
        self.last_used = datetime.utcnow()
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–∞–∂–¥—ã–µ 100 –ø–µ—Ä–µ–¥–∞—á
        if self.total_transmissions % 100 == 0:
            await self.auto_optimize()
    
    async def auto_optimize(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–Ω–∞–ª–∞"""
        if len(self.strength_history) < 10:
            return
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
        recent_strengths = list(self.strength_history)[-10:]
        avg_recent = statistics.mean(recent_strengths)
        
        # –ï—Å–ª–∏ —Å–∏–ª–∞ —Å–Ω–∏–∂–∞–µ—Ç—Å—è, –ø—Ä–æ–±—É–µ–º —É–≤–µ–ª–∏—á–∏—Ç—å learning rate
        if avg_recent < self.current_strength * 0.9:
            self.learning_rate = min(0.1, self.learning_rate * 1.1)
        
        # –ï—Å–ª–∏ —Å–∏–ª–∞ —Å—Ç–∞–±–∏–ª—å–Ω–∞, —É–º–µ–Ω—å—à–∞–µ–º learning rate –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
        elif abs(avg_recent - self.current_strength) < 0.05:
            self.learning_rate = max(0.001, self.learning_rate * 0.9)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –µ—Å–ª–∏ –∫–∞–Ω–∞–ª –ø–æ—á—Ç–∏ –º–µ—Ä—Ç–≤
        if self.current_strength < 0.2 and self.resonance_factor < 0.3:
            await self.emergency_recovery()
        
        self.last_optimized = datetime.utcnow()
    
    async def emergency_recovery(self):
        """–≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞"""
        print(f"[CHANNEL] –≠–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ {self.id}")
        
        # –°–±—Ä–æ—Å –¥–æ –±–∞–∑–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å –Ω–µ–±–æ–ª—å—à–∏–º —É—Å–∏–ª–µ–Ω–∏–µ–º
        self.current_strength = self.base_strength * 1.1
        self.resonance_factor = 1.0
        self.learning_rate = 0.02  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
        
        # –û—á–∏—Å—Ç–∫–∞ —á–∞—Å—Ç–∏ –∏—Å—Ç–æ—Ä–∏–∏
        if len(self.strength_history) > 50:
            self.strength_history = deque(list(self.strength_history)[-50:], maxlen=100)
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
        old_bandwidth = self.max_bandwidth
        self.max_bandwidth = int(self.max_bandwidth * 1.5)
        
        print(f"[CHANNEL] –ö–∞–Ω–∞–ª {self.id} –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. Bandwidth: {old_bandwidth} ‚Üí {self.max_bandwidth}")
    
    def get_health_report(self) -> Dict[str, Any]:
        """–û—Ç—á–µ—Ç –æ –∑–¥–æ—Ä–æ–≤—å–µ –∫–∞–Ω–∞–ª–∞"""
        success_rate = (
            self.successful_transmissions / self.total_transmissions 
            if self.total_transmissions > 0 else 0
        )
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        stability = 0.0
        if len(self.strength_history) > 5:
            recent_strengths = list(self.strength_history)[-5:]
            stability = 1.0 - statistics.stdev(recent_strengths)
        
        return {
            "channel_id": self.id,
            "hebrew_letter": self.hebrew_letter,
            "path": f"{self.from_sephira} ‚Üí {self.to_sephira}",
            "is_active": self.is_active,
            "current_strength": self.current_strength,
            "resonance_factor": self.resonance_factor,
            "load_percentage": (self.current_load / self.max_bandwidth) * 100,
            "success_rate": success_rate,
            "total_transmissions": self.total_transmissions,
            "avg_latency": self.avg_latency,
            "avg_signal_strength": self.avg_signal_strength,
            "stability": stability,
            "health_score": self.calculate_health_score(),
            "last_used": self.last_used.isoformat() if self.last_used else None,
            "recommendations": self.generate_recommendations(),
            "timestamp": datetime.utcnow().isoformat()
        }
    
    def calculate_health_score(self) -> float:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –∑–¥–æ—Ä–æ–≤—å—è –∫–∞–Ω–∞–ª–∞"""
        success_rate = (
            self.successful_transmissions / self.total_transmissions 
            if self.total_transmissions > 0 else 0.5
        )
        
        load_factor = 1.0 - (self.current_load / self.max_bandwidth)
        strength_factor = self.current_strength
        resonance_factor = min(1.0, self.resonance_factor)
        
        weights = {
            "success": 0.4,
            "load": 0.2,
            "strength": 0.25,
            "resonance": 0.15
        }
        
        score = (
            success_rate * weights["success"] +
            load_factor * weights["load"] +
            strength_factor * weights["strength"] +
            resonance_factor * weights["resonance"]
        )
        
        return min(max(score, 0.0), 1.0)
    
    def generate_recommendations(self) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –∫–∞–Ω–∞–ª–∞"""
        recommendations = []
        
        health_score = self.calculate_health_score()
        
        if health_score < 0.3:
            recommendations.append("emergency_recovery_needed")
        elif health_score < 0.6:
            recommendations.append("optimization_recommended")
        
        if self.current_load > self.max_bandwidth * 0.8:
            recommendations.append("reduce_load_or_increase_bandwidth")
        
        if self.resonance_factor < 0.5:
            recommendations.append("improve_resonance_with_sync_signals")
        
        if self.successful_transmissions < 10 and self.total_transmissions > 50:
            recommendations.append("investigate_failure_patterns")
        
        return recommendations


class ChannelLoadBalancer:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫ –Ω–∞–≥—Ä—É–∑–∫–∏ –∫–∞–Ω–∞–ª–æ–≤"""
    
    def __init__(self):
        self.selection_history: deque = deque(maxlen=1000)
        self.channel_performance: Dict[str, Dict[str, Any]] = {}
        self.last_rebalance: Optional[datetime] = None
    
    async def select_best_channel(self, available_channels: List[QuantumChannel], 
                                 signal_type: SignalType, signal_strength: float) -> Optional[QuantumChannel]:
        """
        –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –∫–∞–Ω–∞–ª–∞ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ —Å —É—á–µ—Ç–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        """
        if not available_channels:
            return None
        
        scored_channels = []
        
        for channel in available_channels:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–µ—Ä–µ–¥–∞—á–∏
            can_transmit, reason, effective_strength = await channel.can_transmit(signal_strength)
            
            if not can_transmit:
                continue
            
            # –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞
            score = await self.calculate_channel_score(
                channel, signal_type, effective_strength
            )
            
            scored_channels.append((score, channel, effective_strength, reason))
        
        if not scored_channels:
            return None
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–∫–æ—Ä—É (–≤—ã—Å—à–∏–π —Å–∫–æ—Ä = –ª—É—á—à–∏–π –∫–∞–Ω–∞–ª)
        scored_channels.sort(key=lambda x: x[0], reverse=True)
        
        best_score, best_channel, best_strength, best_reason = scored_channels[0]
        
        # –ó–∞–ø–∏—Å—å –≤ –∏—Å—Ç–æ—Ä–∏—é –≤—ã–±–æ—Ä–∞
        self.selection_history.append({
            "timestamp": datetime.utcnow().isoformat(),
            "channel_id": best_channel.id,
            "signal_type": signal_type.value,
            "score": best_score,
            "strength": best_strength,
            "reason": best_reason,
            "alternatives": len(scored_channels) - 1
        })
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        await self.update_channel_performance(best_channel.id, best_score)
        
        return best_channel
    
    async def calculate_channel_score(self, channel: QuantumChannel, 
                                     signal_type: SignalType, effective_strength: float) -> float:
        """
        –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–∞ –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤—É –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        """
        # –ë–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Å–∏–ª—ã
        base_score = effective_strength * 0.3
        
        # –°–∫–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
        success_rate = (
            channel.successful_transmissions / channel.total_transmissions 
            if channel.total_transmissions > 0 else 0.5
        )
        success_score = success_rate * 0.25
        
        # –°–∫–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑–æ–Ω–∞–Ω—Å–∞
        resonance_score = min(1.0, channel.resonance_factor) * 0.2
        
        # –°–∫–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–≥—Ä—É–∑–∫–∏ (–º–µ–Ω—å—à–µ –Ω–∞–≥—Ä—É–∑–∫–∞ = –ª—É—á—à–µ)
        load_factor = 1.0 - (channel.current_load / channel.max_bandwidth)
        load_score = load_factor * 0.15
        
        # –°–∫–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–∞—Ç–µ–Ω—Ü–∏–∏ (–º–µ–Ω—å—à–µ –ª–∞—Ç–µ–Ω—Ü–∏—è = –ª—É—á—à–µ)
        latency_factor = 1.0 / (1.0 + channel.avg_latency) if channel.avg_latency > 0 else 0.5
        latency_score = latency_factor * 0.1
        
        # –ë–æ–Ω—É—Å—ã/—à—Ç—Ä–∞—Ñ—ã –¥–ª—è —Ç–∏–ø–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
        type_bonus = 0.0
        
        if signal_type == SignalType.QUANTUM_SYNC and channel.resonance_factor > 1.2:
            type_bonus = 0.2  # –ö–≤–∞–Ω—Ç–æ–≤—ã–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ª—é–±—è—Ç –≤—ã—Å–æ–∫–∏–π —Ä–µ–∑–æ–Ω–∞–Ω—Å
        
        elif signal_type == SignalType.EMOTIONAL and channel.current_strength > 0.8:
            type_bonus = 0.15  # –≠–º–æ—Ü–∏–∏ –ª—é–±—è—Ç —Å–∏–ª—å–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
        
        elif signal_type == SignalType.INTENTION and success_rate > 0.8:
            type_bonus = 0.1  # –ù–∞–º–µ—Ä–µ–Ω–∏—è –ª—é–±—è—Ç –Ω–∞–¥–µ–∂–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
        
        # –ò—Ç–æ–≥–æ–≤—ã–π —Å–∫–æ—Ä
        total_score = (
            base_score + 
            success_score + 
            resonance_score + 
            load_score + 
            latency_score + 
            type_bonus
        )
        
        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 0-1
        return min(max(total_score, 0.0), 1.0)
    
    async def update_channel_performance(self, channel_id: str, score: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–Ω–∞–ª–∞"""
        if channel_id not in self.channel_performance:
            self.channel_performance[channel_id] = {
                "scores": deque(maxlen=100),
                "selections": 0,
                "avg_score": 0.0,
                "last_selected": None
            }
        
        perf = self.channel_performance[channel_id]
        perf["scores"].append(score)
        perf["selections"] += 1
        perf["avg_score"] = statistics.mean(perf["scores"]) if perf["scores"] else 0.0
        perf["last_selected"] = datetime.utcnow().isoformat()
    
    async def rebalance_load(self, all_channels: List[QuantumChannel], 
                            target_utilization: float = 0.7):
        """
        –†–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –Ω–∞–≥—Ä—É–∑–∫–∏ –º–µ–∂–¥—É –∫–∞–Ω–∞–ª–∞–º–∏
        """
        now = datetime.utcnow()
        
        # –ù–µ —á–∞—â–µ —á–µ–º —Ä–∞–∑ –≤ 5 –º–∏–Ω—É—Ç
        if (self.last_rebalance and 
            (now - self.last_rebalance).total_seconds() < 300):
            return
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π –Ω–∞–≥—Ä—É–∑–∫–∏
        channel_loads = []
        for channel in all_channels:
            utilization = channel.current_load / channel.max_bandwidth
            channel_loads.append((channel.id, utilization, channel.max_bandwidth))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
        channel_loads.sort(key=lambda x: x[1])
        
        # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Å–∞–º—ã–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –∏ —Å–∞–º—ã–º —Å–≤–æ–±–æ–¥–Ω—ã–º > 30%
        if channel_loads:
            min_load = channel_loads[0][1]
            max_load = channel_loads[-1][1]
            
            if max_load - min_load > 0.3:
                # –†–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞: –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∞—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
                print(f"[BALANCER] –†–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –Ω–∞–≥—Ä—É–∑–∫–∏: min={min_load:.2f}, max={max_load:.2f}")
                
                for i, (channel_id, utilization, bandwidth) in enumerate(channel_loads):
                    channel = next((c for c in all_channels if c.id == channel_id), None)
                    if channel:
                        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø—Ä–æ–ø—É—Å–∫–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
                        if utilization > target_utilization:
                            new_bandwidth = int(bandwidth * 1.1)
                            channel.max_bandwidth = min(200, new_bandwidth)
                            print(f"  ‚Üë {channel.id}: {bandwidth} ‚Üí {channel.max_bandwidth}")
                        
                        # –£–º–µ–Ω—å—à–∞–µ–º —É –æ—á–µ–Ω—å —Å–≤–æ–±–æ–¥–Ω—ã—Ö
                        elif utilization < target_utilization * 0.5:
                            new_bandwidth = int(bandwidth * 0.9)
                            channel.max_bandwidth = max(50, new_bandwidth)
                            print(f"  ‚Üì {channel.id}: {bandwidth} ‚Üí {channel.max_bandwidth}")
        
        self.last_rebalance = now
    
    def get_balancing_report(self) -> Dict[str, Any]:
        """–û—Ç—á–µ—Ç –æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ"""
        if not self.channel_performance:
            return {"total_channels": 0, "avg_selection_score": 0}
        
        avg_scores = [
            perf["avg_score"] 
            for perf in self.channel_performance.values() 
            if perf["avg_score"] > 0
        ]
        
        selection_counts = [
            perf["selections"] 
            for perf in self.channel_performance.values()
        ]
        
        return {
            "total_channels_tracked": len(self.channel_performance),
            "total_selections_recorded": len(self.selection_history),
            "avg_selection_score": statistics.mean(avg_scores) if avg_scores else 0,
            "min_selection_score": min(avg_scores) if avg_scores else 0,
            "max_selection_score": max(avg_scores) if avg_scores else 0,
            "most_selected_channels": sorted(
                [(cid, perf["selections"]) for cid, perf in self.channel_performance.items()],
                key=lambda x: x[1],
                reverse=True
            )[:5],
            "least_selected_channels": sorted(
                [(cid, perf["selections"]) for cid, perf in self.channel_performance.items()],
                key=lambda x: x[1]
            )[:5],
            "rebalance_last_performed": self.last_rebalance.isoformat() if self.last_rebalance else None,
            "timestamp": datetime.utcnow().isoformat()
        }


class SignalTracer:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤"""
    
    def __init__(self):
        self.traces: Dict[str, 'SignalTrace'] = {}
        self.trace_index: Dict[str, List[str]] = defaultdict(list)  # node -> trace_ids
        self.completed_traces: deque = deque(maxlen=1000)
        
    def create_trace(self, signal_package: SignalPackage, source_node: str) -> 'SignalTrace':
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏"""
        trace_id = self._generate_trace_id(signal_package, source_node)
        
        trace = SignalTrace(
            id=trace_id,
            signal_package=signal_package,
            source_node=source_node,
            start_time=datetime.utcnow()
        )
        
        self.traces[trace_id] = trace
        self.trace_index[source_node].append(trace_id)
        
        return trace
    
    def _generate_trace_id(self, signal_package: SignalPackage, source_node: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏"""
        content = f"{source_node}_{signal_package.type}_{signal_package.id}_{datetime.utcnow().timestamp()}"
        return hashlib.sha256(content.encode()).hexdigest()[:16]
    
    async def add_hop(self, trace_id: str, channel: QuantumChannel, 
                     node: SephiroticNode, processing_time: float, 
                     output_strength: float):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à–∞–≥–∞ –≤ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É"""
        if trace_id not in self.traces:
            return
        
        trace = self.traces[trace_id]
        
        hop = {
            "timestamp": datetime.utcnow().isoformat(),
            "channel_id": channel.id,
            "channel_letter": channel.hebrew_letter,
            "from_node": channel.from_sephira,
            "to_node": channel.to_sephira,
            "node_status": node.status.value if node else "unknown",
            "node_resonance": node.resonance if hasattr(node, 'resonance') else 0.0,
            "processing_time": processing_time,
            "output_strength": output_strength,
            "channel_strength": channel.current_strength,
            "channel_resonance": channel.resonance_factor,
            "channel_load": channel.current_load
        }
        
        trace.hops.append(hop)
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø–æ —É–∑–ª—É
        if channel.to_sephira:
            self.trace_index[channel.to_sephira].append(trace_id)
    
    def complete_trace(self, trace_id: str, success: bool, 
                      final_node: str = None, error: str = None):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏"""
        if trace_id not in self.traces:
            return
        
        trace = self.traces[trace_id]
        trace.end_time = datetime.utcnow()
        trace.success = success
        trace.final_node = final_node
        trace.error = error
        
        # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
        if trace.hops:
            trace.total_hops = len(trace.hops)
            trace.total_duration = (trace.end_time - trace.start_time).total_seconds()
            trace.avg_processing_time = statistics.mean(
                [hop["processing_time"] for hop in trace.hops]
            )
            trace.min_strength = min([hop["output_strength"] for hop in trace.hops])
            trace.max_strength = max([hop["output_strength"] for hop in trace.hops])
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–∑–∫–∏—Ö –º–µ—Å—Ç
            bottlenecks = []
            for hop in trace.hops:
                if hop["output_strength"] < 0.3:
                    bottlenecks.append({
                        "channel": hop["channel_letter"],
                        "strength": hop["output_strength"],
                        "reason": "low_strength"
                    })
                elif hop["processing_time"] > 1.0:
                    bottlenecks.append({
                        "channel": hop["channel_letter"],
                        "processing_time": hop["processing_time"],
                        "reason": "high_latency"
                    })
            
            trace.bottlenecks = bottlenecks
        
        # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≤ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ
        self.completed_traces.append(trace)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –∏–∑ –∞–∫—Ç–∏–≤–Ω—ã—Ö (–Ω–æ —Ö—Ä–∞–Ω–∏–º –ø–æ ID –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞)
        # –ù–µ —É–¥–∞–ª—è–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –ø–æ ID
    
    def get_trace(self, trace_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –ø–æ ID"""
        if trace_id in self.traces:
            return self.traces[trace_id].to_dict()
        return None
    
    def get_node_traces(self, node_name: str, limit: int = 10) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–æ–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —É–∑–ª–æ–º"""
        trace_ids = self.trace_index.get(node_name, [])[-limit:]
        traces = []
        
        for trace_id in trace_ids:
            if trace_id in self.traces:
                traces.append(self.traces[trace_id].to_dict())
        
        return traces
    
    def get_recent_traces(self, limit: int = 20) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–æ–∫"""
        recent = list(self.completed_traces)[-limit:]
        return [trace.to_dict() for trace in recent]
    
    def analyze_trace_patterns(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞—Ö"""
        if not self.completed_traces:
            return {"total_traces": 0}
        
        traces = list(self.completed_traces)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
        successful = [t for t in traces if t.success]
        failed = [t for t in traces if not t.success]
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º —Å–∏–≥–Ω–∞–ª–æ–≤
        by_type = defaultdict(list)
        for trace in traces:
            by_type[trace.signal_package.type.value].append(trace)
        
        type_stats = {}
        for sig_type, type_traces in by_type.items():
            if type_traces:
                success_rate = len([t for t in type_traces if t.success]) / len(type_traces)
                avg_hops = statistics.mean([t.total_hops for t in type_traces]) if type_traces else 0
                avg_duration = statistics.mean([t.total_duration for t in type_traces]) if type_traces else 0
                
                type_stats[sig_type] = {
                    "count": len(type_traces),
                    "success_rate": success_rate,
                    "avg_hops": avg_hops,
                    "avg_duration": avg_duration
                }
        
        # –ê–Ω–∞–ª–∏–∑ —É–∑–∫–∏—Ö –º–µ—Å—Ç
        all_bottlenecks = []
        for trace in traces:
            all_bottlenecks.extend(trace.bottlenecks)
        
        bottleneck_stats = defaultdict(int)
        for bottleneck in all_bottlenecks:
            key = f"{bottleneck.get('channel', 'unknown')}_{bottleneck.get('reason', 'unknown')}"
            bottleneck_stats[key] += 1
        
        return {
            "total_traces": len(traces),
            "successful_traces": len(successful),
            "failed_traces": len(failed),
            "overall_success_rate": len(successful) / len(traces) if traces else 0,
            "by_signal_type": type_stats,
            "common_bottlenecks": dict(sorted(bottleneck_stats.items(), key=lambda x: x[1], reverse=True)[:10]),
            "avg_hops_all": statistics.mean([t.total_hops for t in traces]) if traces else 0,
            "avg_duration_all": statistics.mean([t.total_duration for t in traces]) if traces else 0,
            "timestamp": datetime.utcnow().isoformat()
        }


@dataclass
class SignalTrace:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ —Å–∏–≥–Ω–∞–ª–∞"""
    id: str
    signal_package: SignalPackage
    source_node: str
    start_time: datetime
    end_time: Optional[datetime] = None
    success: bool = False
    final_node: Optional[str] = None
    error: Optional[str] = None
    hops: List[Dict[str, Any]] = field(default_factory=list)
    total_hops: int = 0
    total_duration: float = 0.0
    avg_processing_time: float = 0.0
    min_strength: float = 1.0
    max_strength: float = 1.0
    bottlenecks: List[Dict[str, Any]] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            "trace_id": self.id,
            "signal_id": self.signal_package.id,
            "signal_type": self.signal_package.type.value,
            "source_node": self.source_node,
            "target_node": self.signal_package.target,
            "start_time": self.start_time.isoformat(),
            "end_time": self.end_time.isoformat() if self.end_time else None,
            "duration": self.total_duration,
            "success": self.success,
            "final_node": self.final_node,
            "error": self.error,
            "total_hops": self.total_hops,
            "avg_processing_time": self.avg_processing_time,
            "min_strength": self.min_strength,
            "max_strength": self.max_strength,
            "bottlenecks": self.bottlenecks,
            "hops": self.hops[-10:] if self.hops else [],  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —à–∞–≥–æ–≤
            "hop_count": len(self.hops)
        }


class SephiroticBus:
    """–°–û–í–ï–†–®–ï–ù–ù–ê–Ø —Å–µ—Ñ–∏—Ä–æ—Ç–∏—á–µ—Å–∫–∞—è —à–∏–Ω–∞ —Å –ø–æ–ª–Ω–æ–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å—é –∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º"""
    
    def __init__(self, config_file: str = "config/sephirot_channels.yaml"):
        # –Ø–¥—Ä–æ
        self.nodes: Dict[str, SephiroticNode] = {}
        self.channels: Dict[str, QuantumChannel] = {}
        self.channel_connections: Dict[str, List[str]] = defaultdict(list)  # node -> channel_ids
        
        # –ü–æ–¥—Å–∏—Å—Ç–µ–º—ã
        self.tracer = SignalTracer()
        self.load_balancer = ChannelLoadBalancer()
        self.feedback_processor = FeedbackProcessor(self)
        
        # –û—á–µ—Ä–µ–¥–∏
        self.signal_queue = asyncio.PriorityQueue(maxsize=10000)
        self.feedback_queue = asyncio.Queue(maxsize=5000)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        self.metrics = BusMetrics()
        self.health_monitor = BusHealthMonitor(self)
        
        # –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
        self.background_tasks: List[asyncio.Task] = []
        self.is_running = False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self._load_full_channel_config(config_file)
        self._init_background_services()
        
        print(f"[BUS] üå≥ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–∞—è —Å–µ—Ñ–∏—Ä–æ—Ç–∏—á–µ—Å–∫–∞—è —à–∏–Ω–∞")
        print(f"[BUS] üìä –ö–∞–Ω–∞–ª–æ–≤: {len(self.channels)} | –ú–∞–∫—Å. –æ—á–µ—Ä–µ–¥—å: {self.signal_queue.maxsize}")
    
    def _load_full_channel_config(self, config_file: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ 22 –∫–∞–Ω–∞–ª–æ–≤"""
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ YAML
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                channels_config = config.get('channels', [])
                
                for chan_config in channels_config:
                    channel = QuantumChannel(**chan_config)
                    self.channels[channel.id] = channel
                    
                    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤—è–∑–µ–π
                    self.channel_connections[channel.from_sephira].append(channel.id)
                    if channel.direction in [ChannelDirection.BIDIRECTIONAL, ChannelDirection.REVERSE]:
                        self.channel_connections[channel.to_sephira].append(channel.id)
                
                print(f"[BUS] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.channels)} –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞")              
